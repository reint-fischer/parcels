{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delayed starts\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many applications, it is needed to 'delay' the start of particle advection. For example because particles need to be released at different times throughout an experiment. Or because particles need to be released at a constant rate from the same set of locations.\n",
    "\n",
    "This tutorial will show how this can be done. We start with importing the relevant modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from IPython.display import HTML\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "import parcels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import a `FieldSet` (from the Argo example, in this case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CopernicusMarine data in the Agulhas region from the example_datasets\n",
    "example_dataset_folder = parcels.download_example_dataset(\n",
    "    \"CopernicusMarine_data_for_Argo_tutorial\"\n",
    ")\n",
    "\n",
    "ds = xr.open_mfdataset(f\"{example_dataset_folder}/*.nc\", combine=\"by_coords\")\n",
    "ds.load()  # load the dataset into memory\n",
    "\n",
    "fieldset = parcels.FieldSet.from_copernicusmarine(ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining initial `time` as particle release\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the initial times of particles is done when the `ParticleSet` is defined. Although `time` and `z` are optional arguments (with the earliest time in FieldSet and z=0 as defaults), it is good practice to define them explicitly to ensure expected behavior. The simplest way to delay the start of a particle is to use the `time` argument for each particle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note that the `repeatdt` argument used in previous versions of parcels is no longer supported as of v4\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npart = 10  # number of particles to be released\n",
    "lon = 32 * np.ones(npart)\n",
    "lat = np.linspace(-31.5, -30.5, npart, dtype=np.float32)\n",
    "# release every particle one hour later from the initial fieldset time\n",
    "time = ds.time.values[0] + np.arange(0, npart) * np.timedelta64(1, \"h\")\n",
    "z = np.repeat(ds.depth.values[0], npart)\n",
    "\n",
    "pset = parcels.ParticleSet(\n",
    "    fieldset=fieldset, pclass=parcels.Particle, lon=lon, lat=lat, time=time, z=z\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can execute the `pset` as usual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = parcels.ParticleFile(\n",
    "    \"DelayParticle_time.zarr\", outputdt=np.timedelta64(1, \"h\")\n",
    ")\n",
    "\n",
    "pset.execute(\n",
    "    parcels.kernels.AdvectionRK4,\n",
    "    runtime=np.timedelta64(24, \"h\"),\n",
    "    dt=np.timedelta64(5, \"m\"),\n",
    "    output_file=output_file,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then finally, we can show a movie of the particles. Note that the southern-most particles start to move first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "ds_out_out = xr.open_zarr(\"DelayParticle_time.zarr\", decode_times=False)\n",
    "\n",
    "fig = plt.figure(figsize=(7, 5), constrained_layout=True)\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "ax.set_ylabel(\"Latitude [deg N]\")\n",
    "ax.set_xlabel(\"Longitude [deg E]\")\n",
    "ax.set_xlim(31, 33)\n",
    "ax.set_ylim(-32, -30)\n",
    "\n",
    "timerange = np.unique(ds_out_out[\"time\"].values[np.isfinite(ds_out_out[\"time\"])])\n",
    "\n",
    "# Indices of the data where time = 0\n",
    "time_id = np.where(ds_out_out[\"time\"] == timerange[0])\n",
    "\n",
    "sc = ax.scatter(ds_out_out[\"lon\"].values[time_id], ds_out_out[\"lat\"].values[time_id])\n",
    "\n",
    "t = str(timerange[0].astype(\"timedelta64[h]\"))\n",
    "title = ax.set_title(f\"Particles at t = {t}\")\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    t = str(timerange[i].astype(\"timedelta64[h]\"))\n",
    "    title.set_text(f\"Particles at t = {t}\")\n",
    "\n",
    "    time_id = np.where(ds_out_out[\"time\"] == timerange[i])\n",
    "    sc.set_offsets(\n",
    "        np.c_[ds_out_out[\"lon\"].values[time_id], ds_out_out[\"lat\"].values[time_id]]\n",
    "    )\n",
    "\n",
    "\n",
    "anim = FuncAnimation(fig, animate, frames=len(timerange), interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release particles repeatedly at a set frequency using `np.broadcast_to`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you want to repeatedly release particles from the same set of locations, you can expand the initial array of particle release locations. Here we show how to release particles at a set frequency `repeatdt`, for a fixed number of releases `nrepeat`. The total number of particles released is then **nrepeat** x **npart**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npart = 10  # number of particles to be released\n",
    "\n",
    "lon_i = 32 * np.ones(npart)\n",
    "lat_i = np.linspace(-31.5, -30.5, npart, dtype=np.float32)\n",
    "time_i = np.repeat(ds.time.values[0], npart)\n",
    "z_i = np.repeat(ds.depth.values[0], npart)\n",
    "\n",
    "# repeat release at frequency `repeatdt` for `nrepeat` different releases\n",
    "repeatdt = np.timedelta64(6, \"h\")\n",
    "nrepeat = 3\n",
    "\n",
    "lon = np.broadcast_to(lon_i, (nrepeat, npart))\n",
    "lat = np.broadcast_to(lat_i, (nrepeat, npart))\n",
    "time = (\n",
    "    np.broadcast_to(time_i, (nrepeat, npart))\n",
    "    + np.arange(0, nrepeat)[:, np.newaxis] * repeatdt\n",
    ")\n",
    "z = np.broadcast_to(z_i, (nrepeat, npart))\n",
    "\n",
    "pset = parcels.ParticleSet(\n",
    "    fieldset=fieldset, pclass=parcels.Particle, lon=lon, lat=lat, time=time, z=z\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we again define an output file and execute the `pset` as usual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = parcels.ParticleFile(\n",
    "    \"DelayParticle_releasedt.zarr\", outputdt=timedelta(hours=1)\n",
    ")\n",
    "\n",
    "pset.execute(\n",
    "    parcels.kernels.AdvectionRK4,\n",
    "    runtime=timedelta(hours=24),\n",
    "    dt=timedelta(minutes=5),\n",
    "    output_file=output_file,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we get an animation where a new particle is released every 6 hours from each start location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "ds_out = xr.open_zarr(\"DelayParticle_releasedt.zarr\", decode_times=False)\n",
    "\n",
    "fig = plt.figure(figsize=(7, 5), constrained_layout=True)\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "ax.set_ylabel(\"Latitude [deg N]\")\n",
    "ax.set_xlabel(\"Longitude [deg E]\")\n",
    "ax.set_xlim(31, 33)\n",
    "ax.set_ylim(-32, -30)\n",
    "\n",
    "timerange = np.unique(ds_out[\"time\"].values[np.isfinite(ds_out[\"time\"])])\n",
    "\n",
    "# Indices of the data where time = 0\n",
    "time_id = np.where(ds_out[\"time\"] == timerange[0])\n",
    "\n",
    "sc = ax.scatter(ds_out[\"lon\"].values[time_id], ds_out[\"lat\"].values[time_id])\n",
    "\n",
    "t = str(timerange[0].astype(\"timedelta64[h]\"))\n",
    "title = ax.set_title(f\"Particles at t = {t}\")\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    t = str(timerange[i].astype(\"timedelta64[h]\"))\n",
    "    title.set_text(f\"Particles at t = {t}\")\n",
    "\n",
    "    time_id = np.where(ds_out[\"time\"] == timerange[i])\n",
    "    sc.set_offsets(np.c_[ds_out[\"lon\"].values[time_id], ds_out[\"lat\"].values[time_id]])\n",
    "\n",
    "\n",
    "anim = FuncAnimation(fig, animate, frames=len(timerange), interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synced `time` in the output file\n",
    "\n",
    "Note that, because the `outputdt` variable controls the Kernel-loop, all particles are written _at the same time_, even when they start at a non-multiple of `outputdt`.\n",
    "\n",
    "For example, if your particles start at `time=[0, 1, 2]` and `outputdt=2`, then the times written (for `dt=1` and `endtime=4`) will be\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outtime_expected = np.array(\n",
    "    [[0, 2, 4], [2, 4, np.datetime64(\"NaT\")], [2, 4, np.datetime64(\"NaT\")]],\n",
    "    dtype=\"timedelta64[h]\",\n",
    ")\n",
    "print(outtime_expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfilepath = \"DelayParticle_nonmatchingtime.zarr\"\n",
    "\n",
    "pset = parcels.ParticleSet(\n",
    "    fieldset=fieldset,\n",
    "    pclass=parcels.Particle,\n",
    "    lat=[-31] * 3,\n",
    "    lon=[32] * 3,\n",
    "    time=ds.time.values[0] + np.arange(3) * np.timedelta64(1, \"h\"),\n",
    "    z=[0.5] * 3,\n",
    ")\n",
    "\n",
    "output_file = parcels.ParticleFile(outfilepath, outputdt=np.timedelta64(2, \"h\"))\n",
    "pset.execute(\n",
    "    parcels.kernels.AdvectionRK4,\n",
    "    endtime=ds.time.values[0] + np.timedelta64(4, \"h\"),\n",
    "    dt=np.timedelta64(1, \"h\"),\n",
    "    output_file=output_file,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And indeed, the `time` values in the NetCDF output file are as expected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outtime_infile = xr.open_zarr(outfilepath, decode_times=False).time.values[:]\n",
    "print(outtime_infile.astype(\"timedelta64[s]\").astype(\"timedelta64[h]\"))\n",
    "\n",
    "# assert (\n",
    "#     outtime_expected[np.isfinite(outtime_expected)]\n",
    "#     == outtime_infile[np.isfinite(outtime_infile)]\n",
    "# ).all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for some applications, this behavior may be undesirable; for example when particles need to be analyzed at a same age (instead of at a same time). In that case, we recommend either changing `outputdt` so that it is a common divisor of all start times; or doing multiple Parcels runs with subsets of the original `ParticleSet` (e.g., in the example above, one run with the Particles that start at `time=[0, 2]` and one with the Particle at `time=[1]`). In that case, you will get two files:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for times in np.array([[0, 2], [1, 3]]).astype(\"timedelta64[h]\"):\n",
    "    pset = parcels.ParticleSet(\n",
    "        fieldset=fieldset,\n",
    "        pclass=parcels.Particle,\n",
    "        lat=[-31] * len(times),\n",
    "        lon=[32] * len(times),\n",
    "        time=ds.time.values[0] + times,\n",
    "        z=[0.5] * len(times),\n",
    "    )\n",
    "    output_file = parcels.ParticleFile(outfilepath, outputdt=np.timedelta64(2, \"h\"))\n",
    "    pset.execute(\n",
    "        parcels.kernels.AdvectionRK4,\n",
    "        runtime=np.timedelta64(4, \"h\"),\n",
    "        dt=np.timedelta64(1, \"h\"),\n",
    "        output_file=output_file,\n",
    "    )\n",
    "    outtime_infile = xr.open_zarr(outfilepath, decode_times=False).time.values[:]\n",
    "    print(outtime_infile.astype(\"timedelta64[s]\").astype(\"timedelta64[h]\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
